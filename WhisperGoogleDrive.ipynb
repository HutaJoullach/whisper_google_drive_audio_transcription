{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HutaJoullach/whisper_google_drive_audio_transcription/blob/main/WhisperGoogleDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OpenAI Whisper and Google Drive integration for transcribing audio files\n",
        "\n",
        "###This notebook will transcribe all the audio files in a Google Drive folder\n",
        "\n",
        "*Note: This requires giving the application permission to connect to your drive. Only you will have access to the contents of your drive, but please read the warnings carefully.*\n",
        "\n",
        "This notebook application:\n",
        "1. Connects to your Google Drive when you give it permission.\n",
        "2. Creates a WhisperAudio folder and two subfolders (ProcessedAudio and TextFiles.)\n",
        "3. When you run the application it will search for all the audio files (.mp3 and .m4a) in your WhisperAudio folder, transcribe them and then move the file to /ProcessedAudio and save the transcript to /TextFiles.\n",
        "\n",
        "###**For faster performance set your runtime to \"GPU\"**\n",
        "*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n",
        "\n",
        "\n",
        "**Note: If you add a new file after running this application you'll need to remount the drive in step 1 to make them searchable**"
      ],
      "metadata": {
        "id": "mwJYcVNBcKpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Install the required code libraries"
      ],
      "metadata": {
        "id": "6uzeghNJgTgD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDZ2XzKIDLsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce405622-b8c5-44b4-d6f6-8616d1cf0c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-wlifg6n_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-wlifg6n_\n",
            "  Resolved https://github.com/openai/whisper.git to commit 7858aa9c08d98f75575035ecd6481f462d66ca27\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.26.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Fetched 222 kB in 2s (142 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "19 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (23.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.25.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.14.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:36<00:00, 41.5MiB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install librosa\n",
        "\n",
        "import whisper\n",
        "import time\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "import os\n",
        "\n",
        "# model = whisper.load_model(\"tiny.en\")\n",
        "# model = whisper.load_model(\"base.en\")   \n",
        "# model = whisper.load_model(\"small.en\") # load the small model\n",
        "# model = whisper.load_model(\"medium.en\")\n",
        "model = whisper.load_model(\"large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Allow access to your Google Drive and add new folders"
      ],
      "metadata": {
        "id": "4rhtpcTkgKrG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YeXdboeC8eX",
        "outputId": "f9ef9a75-f62c-421e-cd54-ce6aea832e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization.\n",
        "\n",
        "# This will create the WhisperAudio files if they don't exist.\n",
        "folders =  [\"WhisperAudio/\", \"WhisperAudio/ProcessedAudio/\", \"WhisperAudio/TextFiles/\"]\n",
        "for folder in folders:\n",
        "  path = \"/content/drive/MyDrive/\" + folder\n",
        "  if not os.path.exists(path): # Create the folder if it does not exist\n",
        "    os.mkdir(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Upload any audio files you want transcribed in the \"WhisperAudio\" folder in your Google Drive."
      ],
      "metadata": {
        "id": "Qg3uGr5If5oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Let the application search for new files and transcribe the audio files and save them to your Google Drive"
      ],
      "metadata": {
        "id": "tXoptztJ56eH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBmTS6IuPh3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ddb2172-d9aa-4ab6-ef93-5799835d657c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/WhisperAudio/001-sibutomo.mp3\n",
            "Processing 001-sibutomo.mp3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 183/183 [00:00<00:00, 200.79frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:00<00:00, 220.37frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 319.25frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 107/107 [00:00<00:00, 196.97frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:00<00:00, 237.23frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:00<00:00, 172.33frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 252/252 [00:00<00:00, 276.26frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:00<00:00, 151.46frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:00<00:00, 306.84frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 112/112 [00:00<00:00, 296.03frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 words processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 86/86 [00:00<00:00, 198.38frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 words processed\n",
            "Transcription of 001-sibutomo.mp3:\n",
            "\n",
            "無添加のシャボン玉石鹸なら もう安心 天然の保湿成分が含まれるため、肌に潤いを与え、 ごやかに保ちます お肌のことでお悩みの方は ぜひ一度 無添加シャボン玉石鹸をお試しください お求めは 0120 0055 9号まで \n",
            "\n",
            "\n",
            "Saved transcription as /content/drive/MyDrive/WhisperAudio//TextFiles/001-sibutomo.txt\n",
            "Moved /content/drive/MyDrive/WhisperAudio/001-sibutomo.mp3 to /content/drive/MyDrive/WhisperAudio/ProcessedAudio/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load all the audio file paths in a Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization.\n",
        "\n",
        "# Assuming the audio files are in a folder called \"WhisperAudio\" in the root of the drive\n",
        "audio_folder = \"/content/drive/MyDrive/WhisperAudio/\"\n",
        "\n",
        "# Get a list of all the file paths and names in the folder\n",
        "import os\n",
        "audio_files = []\n",
        "audio_names = []\n",
        "for file in os.listdir(audio_folder):\n",
        "  if file.endswith(\".m4a\") or file.endswith(\".mp3\"):\n",
        "    audio_files.append(audio_folder + file)\n",
        "    audio_names.append(file)\n",
        "\n",
        "for f in audio_files:    \n",
        "  print(f)\n",
        "\n",
        "if len(audio_files) == 0:\n",
        "  print(\"You have no files.\")\n",
        "\n",
        "# Loop through the audio files, split each audio file based on pauses in speech then transcribe them with Whisper.\n",
        "for i, file in enumerate(audio_files): # For each audio file\n",
        "  print(f\"Processing {audio_names[i]}...\")\n",
        "  # Load the audio file and convert it to 16 kHz mono\n",
        "  audio, sr = librosa.load(file, sr=16000, mono=True)\n",
        "  # Detect pauses and split the audio. We use a threshold of -30 dB and a minimum pause length of 0.5 seconds.\n",
        "  pauses = librosa.effects.split(audio, top_db=30, frame_length=2048, hop_length=128)\n",
        "  # Transcribe each segment and concatenate the results\n",
        "  transcription = \"\"\n",
        "  for start, end in pauses: # For each segment\n",
        "    segment = audio[start:end]\n",
        "    # Save the segment as a temporary wav file\n",
        "    temp_file = \"temp.wav\"\n",
        "    sf.write(temp_file, segment, sr, subtype='PCM_16')\n",
        "    if os.path.getsize(temp_file) > 10000:\n",
        "      #continue\n",
        "      # Transcribe the segment with Whisper\n",
        "\n",
        "      result = model.transcribe(temp_file, verbose=False, language=\"ja\")\n",
        "      \n",
        "      text = result[\"text\"]\n",
        "      # Append the text to the transcription\n",
        "      print(len(transcription.split(\" \")), \"words processed\")\n",
        "      transcription += text.strip() + \" \"\n",
        "      # Delete the temporary file\n",
        "      os.remove(temp_file)\n",
        "  # Print the transcription\n",
        "  print(f\"Transcription of {audio_names[i]}:\\n\")\n",
        "  print(transcription)\n",
        "  print(\"\\n\")\n",
        " \n",
        "  # Convert the spaces between sections into paragraph breaks and save the transcription as a txt document in the same folder as MyAudio.\n",
        "  transcription = re.sub(r\"\\s\\s+\", \"\\n\\n\", transcription) # Replace multiple spaces with newlines\n",
        "  text_file = audio_folder + \"/TextFiles/\" + audio_names[i][:-4] + \".txt\" # Create the text file name\n",
        "  with open(text_file, \"w\") as f: # Write the transcription to the text file\n",
        "    f.write(transcription)\n",
        "  print(f\"Saved transcription as {text_file}\")\n",
        "\n",
        "# Move the audio files to \"/content/drive/MyDrive/WhisperAudio/Processed\"\n",
        "import shutil\n",
        "processed_folder = \"/content/drive/MyDrive/WhisperAudio/ProcessedAudio/\"\n",
        "if not os.path.exists(processed_folder): # Create the folder if it does not exist\n",
        "  os.mkdir(processed_folder)\n",
        "for file in audio_files: # Move each audio file to the processed folder\n",
        "  shutil.move(file, processed_folder + os.path.basename(file))\n",
        "  print(f\"Moved {file} to {processed_folder}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}